{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de67e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA METHOD WITH REPORTING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def reduce_pca_by_variance(data: np.ndarray, feature_names: list, variance_threshold: float):\n",
    "    \"\"\"\n",
    "    Performs PCA on n-dimensional data, automatically selecting the minimum\n",
    "    number of components to explain at least the `variance_threshold`.\n",
    "    \n",
    "    This modified version also prints the results of the reduction and\n",
    "    the top 5 feature contributors for each component.\n",
    "\n",
    "    Args:\n",
    "        data: A (n_samples, n_features) NumPy array.\n",
    "        feature_names: A list of strings corresponding to the feature columns\n",
    "                       in `data`. (e.g., list(df.columns))\n",
    "        variance_threshold: The target amount of variance to explain\n",
    "                            (e.g., 0.95 for 95%).\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - data_transformed (np.ndarray): The data projected onto the\n",
    "                                         new component space.\n",
    "        - fitted_pca (PCA): The fitted PCA object, which you can use\n",
    "                            to inspect the number of components, etc.\n",
    "        - explained_variance_list (list): A list of the variance explained\n",
    "                                          by each component (e.g., [0.5, 0.3]).\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(feature_names) != data.shape[1]:\n",
    "        raise ValueError(f\"Number of feature_names ({len(feature_names)}) does not \"\n",
    "                         f\"match number of data columns ({data.shape[1]}).\")\n",
    "\n",
    "    # 1. Create a PCA object with the variance threshold.\n",
    "    # By setting n_components to a float, PCA automatically finds\n",
    "    # the components needed to explain that much variance.\n",
    "    pca = PCA(n_components=variance_threshold)\n",
    "    \n",
    "    # 2. Create a pipeline to first scale the data, then run PCA.\n",
    "    # Scaling is crucial for PCA to work correctly.\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', pca)\n",
    "    ])\n",
    "    \n",
    "    # 3. Fit the pipeline to the data and transform it\n",
    "    data_transformed = pipeline.fit_transform(data)\n",
    "    \n",
    "    # --- Report print statements ---\n",
    "    \n",
    "    # Get the original and new dimensions\n",
    "    original_dimensions = data.shape[1]\n",
    "    # We access the fitted pca object from step 2\n",
    "    new_dimensions = pca.n_components_ \n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(\"PCA Dimensionality Reduction Report\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Original dimensions:   {original_dimensions}\")\n",
    "    print(f\"New dimensions:        {new_dimensions}\")\n",
    "    print(f\"Dimensions reduced by: {original_dimensions - new_dimensions}\")\n",
    "    print(\"\\nVariance explained by each remaining component:\")\n",
    "    \n",
    "    # pca.explained_variance_ratio_ is an array like [0.5, 0.3, 0.1]\n",
    "    for i, variance in enumerate(pca.explained_variance_ratio_):\n",
    "        print(f\"  Principal Component {i+1}: {variance * 100:.2f}%\")\n",
    "        \n",
    "    # Print total variance explained\n",
    "    total_variance = np.sum(pca.explained_variance_ratio_)\n",
    "    print(f\"\\nTotal variance explained: {total_variance * 100:.2f}%\")\n",
    "    print(f\"(Target threshold was {variance_threshold * 100:.0f}%)\")\n",
    "    \n",
    "    # --- New: Top 5 Contributors per Component Report ---\n",
    "    print(\"\\nTop 5 Contributors per Component:\")\n",
    "    \n",
    "    # pca.components_ has shape (n_components, n_features)\n",
    "    for i, component in enumerate(pca.components_):\n",
    "        print(f\"  --- Principal Component {i+1} ---\")\n",
    "        \n",
    "        # Get indices of the top 5 absolute loadings\n",
    "        # np.argsort returns indices of smallest to largest\n",
    "        # We take the last 5, and then reverse them [::-1]\n",
    "        top_5_indices = np.argsort(np.abs(component))[-5:][::-1]\n",
    "        \n",
    "        # Print the feature name and its loading (weight)\n",
    "        for j, feature_index in enumerate(top_5_indices):\n",
    "            feature_name = feature_names[feature_index]\n",
    "            loading = component[feature_index]\n",
    "            print(f\"    {j+1}. {feature_name}: {loading:.4f}\")\n",
    "            \n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # --- End of report ---\n",
    "    \n",
    "    # Get the list of explained variances\n",
    "    explained_variance_list = pca.explained_variance_ratio_.tolist()\n",
    "    \n",
    "    # Return the new data, the fitted PCA object, and the list of variances\n",
    "    return data_transformed, pca, explained_variance_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c89e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: networkx\n",
      "Successfully installed networkx-3.2.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb264f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_98dc148dc1284f588ceea6e9d96923bd/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_98dc148dc1284f588ceea6e9d96923bd/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-pip-egg-info-88gbnlbc\n",
      "         cwd: /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_98dc148dc1284f588ceea6e9d96923bd/\n",
      "    Complete output (15 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/46/1c/395a83ee7b2d2ad7a05b453872053d41449564477c81dc356f720b16eac4/sklearn-0.0.post12.tar.gz#sha256=54cff9e20839b7b202321178228af4d9388bedf78425d9299fd9ee170d68802e (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post11.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_32ac7626dadd4bd1b8ccc1623fdf54f6/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_32ac7626dadd4bd1b8ccc1623fdf54f6/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-pip-egg-info-x461e9ap\n",
      "         cwd: /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_32ac7626dadd4bd1b8ccc1623fdf54f6/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/a4/0b/d1c703256cf293be77b7db44dbef62251fe02a97d0bef981f7120b0b0c0f/sklearn-0.0.post11.tar.gz#sha256=af035c4f0b970b7fc2d3856079aa1aa1032df3d7f65048a9d87114abf13c4629 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post10.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_7cb5475be8a0433c9e807fb7efbd292b/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_7cb5475be8a0433c9e807fb7efbd292b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-pip-egg-info-4llbiyqp\n",
      "         cwd: /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_7cb5475be8a0433c9e807fb7efbd292b/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b9/0e/b2a4cfaa9e12b9ca4c71507bc26d2c99d75de172c0088c9835a98cf146ff/sklearn-0.0.post10.tar.gz#sha256=d4cd5a2e64b3caaf82cd5e33c46884dfeec5ebf991710d9faeb4fe81cadb3ba6 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_7e9408eb96df4233bd937407b6c0a463/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_7e9408eb96df4233bd937407b6c0a463/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-pip-egg-info-tkfvay3o\n",
      "         cwd: /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_7e9408eb96df4233bd937407b6c0a463/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/28/86/207a003339023247fef1bb5bc9f5093140d17294b2f6d15bfcd4885e469e/sklearn-0.0.post9.tar.gz#sha256=1ff5864cf30489ee48a014fe8f4320d7bb59592392a4ef52ae9d7a37942615ac (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post7.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_f05bf2b185e342d1817cda84ec7e7c2c/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_f05bf2b185e342d1817cda84ec7e7c2c/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-pip-egg-info-ft5tnjwd\n",
      "         cwd: /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_f05bf2b185e342d1817cda84ec7e7c2c/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/70/ce/81aa643f3c43488c4a1e417e45f696a61e7ac82b57190fad3c310df2c07b/sklearn-0.0.post7.tar.gz#sha256=1c89020b364fdc3aa2839e0ae34e8f0b406669e4b5c2359dda3ac398f9c76874 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_08600ab3ae134502bbcd3da466beb51e/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_08600ab3ae134502bbcd3da466beb51e/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-pip-egg-info-sbxtpz6a\n",
      "         cwd: /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_08600ab3ae134502bbcd3da466beb51e/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/7a/93/e0e1b1e98f39dfca7ec9795cb46f6e09e88a2fd5d4a28e4b3d1f618a2aec/sklearn-0.0.post5.tar.gz#sha256=7377c714a03a79bbe9196f435db931fd2a6fa8c68514da7ed3a251fd08c52e2c (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_d8325a92107444e98991fe146f16def7/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_d8325a92107444e98991fe146f16def7/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-pip-egg-info-vhrzmrc6\n",
      "         cwd: /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_d8325a92107444e98991fe146f16def7/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/99/b2/165110013aa66fae6fc13918ad0e9de4801e5f1691d371bf8b63328037e6/sklearn-0.0.post4.tar.gz#sha256=0e81ec9c32d4bb418e7be8f1ec1027d174975502dc84cbc4f4564b4cba31e674 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Developer/CommandLineTools/usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_b6cfbb0ce4f948f084f98efad1a7af1f/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_b6cfbb0ce4f948f084f98efad1a7af1f/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-pip-egg-info-a6w30tgw\n",
      "         cwd: /private/var/folders/kp/24jrww7s5rq2cp13x34d48yw0000gn/T/pip-install-fzv2nfqg/sklearn_b6cfbb0ce4f948f084f98efad1a7af1f/\n",
      "    Complete output (18 lines):\n",
      "    The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "    rather than 'sklearn' for pip commands.\n",
      "    \n",
      "    Here is how to fix this error in the main use cases:\n",
      "    - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "    - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "      (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "    - if the 'sklearn' package is used by one of your dependencies,\n",
      "      it would be great if you take some time to track which package uses\n",
      "      'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "    - as a last resort, set the environment variable\n",
      "      SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "    \n",
      "    More information is available at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package\n",
      "    \n",
      "    If the previous advice does not cover your use case, feel free to report it at\n",
      "    https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/db/1e/af4e9cded5093a92e60d4ae7149a02c7427661b2db66c8ea4d34b17864a2/sklearn-0.0.post1.tar.gz#sha256=76b9ed1623775168657b86b5fe966d45752e5c87f528de6240c38923b94147c5 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /Users/ishankanade/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sklearn) (2.0.2)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.3 MB 764 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=b2c910cf2dfe2d0e4bcbfb9f6890952d89263065c37a1a6f3d56ee8bb3e8ccb2\n",
      "  Stored in directory: /Users/ishankanade/Library/Caches/pip/wheels/e4/7b/98/b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.6.1 scipy-1.13.1 sklearn-0.0 threadpoolctl-3.6.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4cff72",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8919de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data to be a numpy array probably\n",
    "df=pd.read_csv('consolidated_acs_data_clean.csv')\n",
    "data=np.array(df)\n",
    "income_index=1  # Example index for income dimension\n",
    "# Transform the income dimension by logarithmic scale\n",
    "data[:, income_index] = np.log(data[:, income_index].astype(np.float64))\n",
    "# Normalize data by dividing by standard deviation by dimension\n",
    "for i in range(1,data.shape[1]):\n",
    "    data[:, i] = data[:, i] / np.std(data[:, i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24198e26",
   "metadata": {},
   "source": [
    "## Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465a4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize weights, and scale data by weights\n",
    "# Get column indices\n",
    "income_index = 1  # per_capita_income\n",
    "poverty_index = df.columns.get_loc('avg_poverty_ratio')\n",
    "employment_index = df.columns.get_loc('in_labor_force')\n",
    "healthcare_index = df.columns.get_loc('Educational services, and health care and social assistance')\n",
    "education_index = df.columns.get_loc('College or More')\n",
    "commute_index = df.columns.get_loc('avg_commute_time')\n",
    "housing_index = df.columns.get_loc('avg_housing_cost_burden')\n",
    "race_indices = [df.columns.get_loc(col) for col in ['white', 'black', 'asian', 'native', 'pacific islander', 'other']]\n",
    "\n",
    "# Apply dimension weights\n",
    "data[:, income_index] *= 0.1225          # Economic Security - Income\n",
    "data[:, poverty_index] *= 0.0525         # Economic Security - Poverty\n",
    "data[:, employment_index] *= 0.07        # Economic Security - Employment\n",
    "data[:, healthcare_index] *= 0.105       # Economic Security - Healthcare\n",
    "data[:, education_index] *= 0.15         # Education\n",
    "data[:, commute_index] *= 0.15           # Location Affordability - Transportation\n",
    "data[:, housing_index] *= 0.15           # Location Affordability - Housing\n",
    "\n",
    "# Race: distribute 0.2 across 6 race columns\n",
    "for idx in race_indices:\n",
    "    data[:, idx] *= 0.2 / 6  # 0.0333 per column\n",
    "\n",
    "weights = np.array([\n",
    "    0.1225,     # 1:  per_capita_income (Economic Security - Income)\n",
    "    0.2/6,      # 2:  white (Cultural - Race)\n",
    "    0.2/6,      # 3:  black (Cultural - Race)\n",
    "    0.2/6,      # 4:  asian (Cultural - Race)\n",
    "    0.2/6,      # 5:  native (Cultural - Race)\n",
    "    0.2/6,      # 6:  pacific islander (Cultural - Race)\n",
    "    0.2/6,      # 7:  other (Cultural - Race)\n",
    "    0.0,        # 8:  Under High School (not weighted)\n",
    "    0.0,        # 9:  High School (No College Degree) (not weighted)\n",
    "    0.15,       # 10: College or More (Education)\n",
    "    0.0,        # 11: Agriculture (not weighted)\n",
    "    0.0,        # 12: Construction_and_manufacturing (not weighted)\n",
    "    0.0,        # 13: trade (not weighted)\n",
    "    0.0,        # 14: Transportation and warehousing (not weighted)\n",
    "    0.0,        # 15: nerds (not weighted)\n",
    "    0.105,      # 16: Educational services, and health care (Economic Security - Healthcare)\n",
    "    0.0,        # 17: finance_inurance_and_realty (not weighted)\n",
    "    0.0,        # 18: other_services (not weighted)\n",
    "    0.07,       # 19: in_labor_force (Economic Security - Employment)\n",
    "    0.0,        # 20: out_labor_force (not weighted)\n",
    "    0.15,       # 21: avg_commute_time (Location Affordability - Transportation)\n",
    "    0.15,       # 22: avg_housing_cost_burden (Location Affordability - Housing)\n",
    "    0.0525,     # 23: avg_poverty_ratio (Economic Security - Poverty)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2c9730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "PCA Dimensionality Reduction Report\n",
      "------------------------------\n",
      "Original dimensions:   23\n",
      "New dimensions:        6\n",
      "Dimensions reduced by: 17\n",
      "\n",
      "Variance explained by each remaining component:\n",
      "  Principal Component 1: 16.07%\n",
      "  Principal Component 2: 10.11%\n",
      "  Principal Component 3: 8.43%\n",
      "  Principal Component 4: 6.79%\n",
      "  Principal Component 5: 6.32%\n",
      "  Principal Component 6: 5.67%\n",
      "\n",
      "Total variance explained: 53.38%\n",
      "(Target threshold was 50%)\n",
      "\n",
      "Top 5 Contributors per Component:\n",
      "  --- Principal Component 1 ---\n",
      "    1. College or More: 0.4448\n",
      "    2. avg_poverty_ratio: 0.3872\n",
      "    3. Under High School: -0.3443\n",
      "    4. per_capita_income: 0.2592\n",
      "    5. in_labor_force: 0.2370\n",
      "  --- Principal Component 2 ---\n",
      "    1. out_labor_force: 0.4101\n",
      "    2. in_labor_force: -0.4101\n",
      "    3. white: 0.3803\n",
      "    4. pacific islander: 0.3752\n",
      "    5. Agriculture, forestry, fishing and hunting, and mining: 0.2772\n",
      "  --- Principal Component 3 ---\n",
      "    1. High School (No College Degree): 0.4196\n",
      "    2. avg_housing_cost_burden: -0.4130\n",
      "    3. white: 0.3610\n",
      "    4. Construction_and_manufacturing: 0.3370\n",
      "    5. asian: -0.2544\n",
      "  --- Principal Component 4 ---\n",
      "    1. other: 0.4171\n",
      "    2. Under High School: 0.3589\n",
      "    3. black: -0.3423\n",
      "    4. Educational services, and health care and social assistance: -0.2938\n",
      "    5. out_labor_force: -0.2873\n",
      "  --- Principal Component 5 ---\n",
      "    1. other: 0.4635\n",
      "    2. in_labor_force: -0.4026\n",
      "    3. out_labor_force: 0.4026\n",
      "    4. pacific islander: -0.4001\n",
      "    5. native: -0.2099\n",
      "  --- Principal Component 6 ---\n",
      "    1. other_services: 0.6451\n",
      "    2. black: -0.3944\n",
      "    3. avg_commute_time: -0.3466\n",
      "    4. Transportation and warehousing, and utilities: -0.3019\n",
      "    5. white: 0.2319\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Perform PCA, and project onto the top N dimensions so that they explain 50% of the variance\n",
    "new_data,pca,var_explained = reduce_pca_by_variance(data[:,1:], list(df.columns)[1:], variance_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a20fbd0",
   "metadata": {},
   "source": [
    "As shown, the first component has a distinct identity, namely education, income and poverty, part of the most important factors typically considered as determinant of a person's sociol-economic status. The rest of the components are a mixed of race, education, occupation, and comute time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a5f4c0",
   "metadata": {},
   "source": [
    "# Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925f1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dimension_layered_knn(data, dimension_weights, k=10):\n",
    "    \"\"\"\n",
    "    Create multi-layer network where each dimension has its own KNN graph.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for i in range(data.shape[0]):\n",
    "        G.add_node(i)\n",
    "    \n",
    "    # For each dimension, create KNN graph\n",
    "    for dim in range(data.shape[1]):\n",
    "        dim_weight = dimension_weights[dim]\n",
    "        \n",
    "        if dim_weight == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get this dimension's values (1D)\n",
    "        dim_data = data[:, dim].reshape(-1, 1)\n",
    "        \n",
    "        # Build KNN graph for THIS dimension only\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        nbrs = NearestNeighbors(n_neighbors=k)\n",
    "        nbrs.fit(dim_data)\n",
    "        distances, indices = nbrs.kneighbors(dim_data)\n",
    "        \n",
    "        # Add edges weighted by dimension importance\n",
    "        for i in range(len(data)):\n",
    "            for j, neighbor in enumerate(indices[i]):\n",
    "                if i != neighbor:\n",
    "                    if G.has_edge(i, neighbor):\n",
    "                        G[i][neighbor]['weight'] += dim_weight  # Accumulate\n",
    "                    else:\n",
    "                        G.add_edge(i, neighbor, weight=dim_weight)\n",
    "    \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c6ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ring_network import construct_net\n",
    "G = create_dimension_layered_knn(new_data, dimension_weights=var_explained, k=10)\n",
    "G_uni= nx.Graph()\n",
    "G_uni.add_nodes_from(G.nodes(data=True))\n",
    "G_uni.add_edges_from(G.edges())\n",
    "\n",
    "# Gring= construct_net(new_data,var_explained,0.2)\n",
    "# Gring_uni= nx.Graph()\n",
    "# Gring_uni.add_nodes_from(Gring.nodes(data=True))\n",
    "# Gring_uni.add_edges_from(Gring.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c43134",
   "metadata": {},
   "source": [
    "## Geographic weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7545ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Create graph\n",
    "Geo = G.copy()\n",
    "#Gring_geo=Gring.copy()\n",
    "# Load adjacency matrix\n",
    "adj_matrix = load_npz('adjacency_queen_matrix.npz')\n",
    "\n",
    "# Load mappings\n",
    "with open('adjacency_queen_mappings.pkl', 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "index_to_geoid = mappings['index_to_geoid']\n",
    "\n",
    "# Get edges from sparse matrix\n",
    "rows, cols = adj_matrix.nonzero()\n",
    "\n",
    "# Add edges with your weight\n",
    "weight = 2  # Change this to your desired weight\n",
    "\n",
    "for i, j in zip(rows, cols):\n",
    "    if i < j:  # Only add each edge once (undirected)\n",
    "        geoid1 = index_to_geoid[i]\n",
    "        geoid2 = index_to_geoid[j]\n",
    "        Geo.add_edge(i, j, weight=weight)\n",
    "        #Gring_geo.add_edge(i, j, weight=weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef6e53",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812afc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K means clustering function\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def get_kmeans_partition(data: np.ndarray, weights, n_clusters=14):\n",
    "    \"\"\"\n",
    "    Runs K-means clustering on the input data and returns the loss\n",
    "    (inertia) and a partition of the data indices by cluster.\n",
    "\n",
    "    Args:\n",
    "        data: A (n_samples, n_features) NumPy array.\n",
    "        n_clusters: The number of clusters (k).\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - loss (float): The inertia (Within-Cluster Sum of Squares).\n",
    "        - partitions (dict): A dictionary where keys are cluster IDs (0 to k-1)\n",
    "                             and values are lists of original data indices\n",
    "                             belonging to that cluster.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Initialize and fit the K-means model\n",
    "    # n_init=10 runs the algorithm 10 times and picks the best result\n",
    "    # random_state=42 ensures the result is reproducible\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    for i in range(len(weights)):\n",
    "        data[:, i] = data[:, i] * weights[i]\n",
    "    kmeans.fit(data)\n",
    "\n",
    "    # 2. Get the loss (inertia)\n",
    "    # .inertia_ is the WCSS (Within-Cluster Sum of Squares)\n",
    "    loss = kmeans.inertia_\n",
    "\n",
    "    # 3. Get the cluster assignment for each data point\n",
    "    # .labels_ is an array like [0, 1, 1, 0, 2, ...]\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # 4. Create the partition of indices\n",
    "    partitions = {i: [] for i in range(n_clusters)}\n",
    "    for index, cluster_id in enumerate(labels):\n",
    "        partitions[cluster_id].append(index)\n",
    "\n",
    "    return loss, partitions\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "def calculate_kmeans_loss_for_partition(data: np.ndarray, partition: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the K-means \"loss\" (Inertia, or Within-Cluster Sum of Squares)\n",
    "    for a given dataset and a user-provided partition.\n",
    "\n",
    "    Args:\n",
    "        data: A (n_samples, n_features) NumPy array.\n",
    "        partition: A list of lists, where each inner list contains the\n",
    "                   *indices* (row numbers) of the data points belonging\n",
    "                   to that cluster.\n",
    "                   Example: [[0, 1, 4], [2, 3, 5]]\n",
    "\n",
    "    Returns:\n",
    "        total_loss (float): The total K-means loss (Inertia) for this partition.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Iterate over each cluster (which is a list of indices)\n",
    "    for indices in partition:\n",
    "        \n",
    "        # 1. Get all data points belonging to this cluster\n",
    "        # Using [indices, :] selects all rows whose index is in the list\n",
    "        cluster_points = data[indices, :]\n",
    "        \n",
    "        # Handle empty clusters (their loss is 0)\n",
    "        if cluster_points.shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        # 2. Calculate the \"true\" centroid (mean) for this cluster\n",
    "        # axis=0 calculates the mean of each *column* (feature)\n",
    "        centroid = np.mean(cluster_points, axis=0)\n",
    "        \n",
    "        # 3. Calculate the sum of squared distances from each point to the centroid\n",
    "        #    - (cluster_points - centroid) uses broadcasting to get distance vectors\n",
    "        #    - (** 2) squares all distances\n",
    "        #    - np.sum(...) sums all squared distances into a single number\n",
    "        cluster_loss = np.sum((cluster_points - centroid) ** 2)\n",
    "        \n",
    "        # 4. Add this cluster's loss to the total\n",
    "        total_loss += cluster_loss\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "k = 14\n",
    "\n",
    "# 3. Run the function\n",
    "total_loss, index_partitions = get_kmeans_partition(new_data,weights=var_explained, n_clusters=k)\n",
    "\n",
    "index_partitions=[index_partitions[i] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854aa88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of 100 | elapsed: 17.0min remaining:   42.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DONE ===\n",
      "\n",
      "G_num_comms: mean=16.3500, std=1.1347\n",
      "Geo_num_comms: mean=22.1800, std=1.2440\n",
      "G_uni_num_comms: mean=16.7400, std=2.6669\n",
      "cluster_size_std_Geo: mean=113.9136, std=14.1228\n",
      "G_modularity_self: mean=0.2859, std=0.0012\n",
      "Geo_modularity_self: mean=0.5183, std=0.0008\n",
      "G_uni_modularity_self: mean=0.1467, std=0.0056\n",
      "G_modularity_GeoPartition: mean=0.0100, std=0.0008\n",
      "G_modularity_GuniPartition: mean=0.1548, std=0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 17.2min finished\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "NUM_RUNS = 100\n",
    "\n",
    "def run_one_iteration(run, G, Geo, G_uni):\n",
    "    partG = nx.algorithms.community.louvain_communities(G, weight='weight', resolution=0.75)\n",
    "    partGeo = nx.algorithms.community.louvain_communities(Geo, weight='weight', resolution=0.8)\n",
    "    partG_uni = nx.algorithms.community.louvain_communities(G_uni, weight='weight', resolution=0.95)\n",
    "\n",
    "    return {\n",
    "        \"G_num_comms\": len(partG),\n",
    "        \"Geo_num_comms\": len(partGeo),\n",
    "        \"G_uni_num_comms\": len(partG_uni),\n",
    "\n",
    "        \"cluster_size_std_Geo\": np.std([len(x) for x in partGeo]),\n",
    "\n",
    "        \"G_modularity_self\": nx.algorithms.community.modularity(G, partG, weight='weight'),\n",
    "        \"Geo_modularity_self\": nx.algorithms.community.modularity(Geo, partGeo, weight='weight'),\n",
    "        \"G_uni_modularity_self\": nx.algorithms.community.modularity(G_uni, partG_uni, weight='weight'),\n",
    "\n",
    "        \"G_modularity_GeoPartition\": nx.algorithms.community.modularity(G, partGeo, weight='weight'),\n",
    "        \"G_modularity_GuniPartition\": nx.algorithms.community.modularity(G, partG_uni, weight='weight'),\n",
    "    }\n",
    "\n",
    "results_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_one_iteration)(run, G, Geo, G_uni)\n",
    "    for run in range(NUM_RUNS)\n",
    ")\n",
    "\n",
    "results = {\n",
    "    \"G_num_comms\": [],\n",
    "    \"Geo_num_comms\": [],\n",
    "    \"G_uni_num_comms\": [],\n",
    "    \"cluster_size_std_Geo\": [],\n",
    "    \"G_modularity_self\": [],\n",
    "    \"Geo_modularity_self\": [],\n",
    "    \"G_uni_modularity_self\": [],\n",
    "    \"G_modularity_GeoPartition\": [],\n",
    "    \"G_modularity_GuniPartition\": [],\n",
    "}\n",
    "\n",
    "for r in results_list:\n",
    "    for key in results:\n",
    "        results[key].append(r[key])\n",
    "\n",
    "print(\"\\n=== DONE ===\\n\")\n",
    "\n",
    "for key in results:\n",
    "    arr = np.array(results[key])\n",
    "    print(\"{}: mean={:.4f}, std={:.4f}\".format(key, arr.mean(), arr.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfc24f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 16,\n",
       "  'cluster_size_std_Geo': np.float64(88.8532912862588),\n",
       "  'G_modularity_self': 0.2865562682786773,\n",
       "  'Geo_modularity_self': 0.5183172147786919,\n",
       "  'G_uni_modularity_self': 0.14615496944253792,\n",
       "  'G_modularity_GeoPartition': 0.010055089876113265,\n",
       "  'G_modularity_GuniPartition': 0.15456999197569918},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(113.77487013563307),\n",
       "  'G_modularity_self': 0.2868538434107725,\n",
       "  'Geo_modularity_self': 0.5182789886666312,\n",
       "  'G_uni_modularity_self': 0.1560686190732063,\n",
       "  'G_modularity_GeoPartition': 0.01138045729750721,\n",
       "  'G_modularity_GuniPartition': 0.16418119230486838},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 21,\n",
       "  'cluster_size_std_Geo': np.float64(102.07594361008321),\n",
       "  'G_modularity_self': 0.284644987832289,\n",
       "  'Geo_modularity_self': 0.5188751278070335,\n",
       "  'G_uni_modularity_self': 0.1421948045983672,\n",
       "  'G_modularity_GeoPartition': 0.009073289393462603,\n",
       "  'G_modularity_GuniPartition': 0.15231059112941675},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 19,\n",
       "  'G_uni_num_comms': 12,\n",
       "  'cluster_size_std_Geo': np.float64(107.31045907104665),\n",
       "  'G_modularity_self': 0.28764065331322,\n",
       "  'Geo_modularity_self': 0.5164145148886512,\n",
       "  'G_uni_modularity_self': 0.1561122977541709,\n",
       "  'G_modularity_GeoPartition': 0.010956007614216667,\n",
       "  'G_modularity_GuniPartition': 0.16254076679935964},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 25,\n",
       "  'G_uni_num_comms': 16,\n",
       "  'cluster_size_std_Geo': np.float64(100.53576478049989),\n",
       "  'G_modularity_self': 0.2840273072712829,\n",
       "  'Geo_modularity_self': 0.5194587316405656,\n",
       "  'G_uni_modularity_self': 0.1471188354150472,\n",
       "  'G_modularity_GeoPartition': 0.00905493085499608,\n",
       "  'G_modularity_GuniPartition': 0.1608287766137827},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(131.78901574562963),\n",
       "  'G_modularity_self': 0.28492416728661757,\n",
       "  'Geo_modularity_self': 0.5163760102100441,\n",
       "  'G_uni_modularity_self': 0.14395756613737584,\n",
       "  'G_modularity_GeoPartition': 0.010379362360278654,\n",
       "  'G_modularity_GuniPartition': 0.15272303920052988},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 25,\n",
       "  'G_uni_num_comms': 15,\n",
       "  'cluster_size_std_Geo': np.float64(104.11147871392473),\n",
       "  'G_modularity_self': 0.28635596057014695,\n",
       "  'Geo_modularity_self': 0.5192289731255438,\n",
       "  'G_uni_modularity_self': 0.1494420752830216,\n",
       "  'G_modularity_GeoPartition': 0.009742412097402352,\n",
       "  'G_modularity_GuniPartition': 0.1519210091312488},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 19,\n",
       "  'G_uni_num_comms': 16,\n",
       "  'cluster_size_std_Geo': np.float64(94.0546196002304),\n",
       "  'G_modularity_self': 0.2879788793716813,\n",
       "  'Geo_modularity_self': 0.5171688730189038,\n",
       "  'G_uni_modularity_self': 0.1458076838224748,\n",
       "  'G_modularity_GeoPartition': 0.010254535312721885,\n",
       "  'G_modularity_GuniPartition': 0.15816056518581448},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(106.36554971084038),\n",
       "  'G_modularity_self': 0.28638868031835,\n",
       "  'Geo_modularity_self': 0.5181812242145631,\n",
       "  'G_uni_modularity_self': 0.15782221307957905,\n",
       "  'G_modularity_GeoPartition': 0.009621619430057795,\n",
       "  'G_modularity_GuniPartition': 0.15935497517313457},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(149.28433267919),\n",
       "  'G_modularity_self': 0.28815949651080675,\n",
       "  'Geo_modularity_self': 0.5166804638263534,\n",
       "  'G_uni_modularity_self': 0.15117950381235926,\n",
       "  'G_modularity_GeoPartition': 0.010823106182413068,\n",
       "  'G_modularity_GuniPartition': 0.15647483054391914},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(103.54553589863326),\n",
       "  'G_modularity_self': 0.2846948371511465,\n",
       "  'Geo_modularity_self': 0.5178350658754478,\n",
       "  'G_uni_modularity_self': 0.15672436320887909,\n",
       "  'G_modularity_GeoPartition': 0.00854172097451187,\n",
       "  'G_modularity_GuniPartition': 0.1622761020566792},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 12,\n",
       "  'cluster_size_std_Geo': np.float64(108.66668462370349),\n",
       "  'G_modularity_self': 0.28462346740197914,\n",
       "  'Geo_modularity_self': 0.5180840640723132,\n",
       "  'G_uni_modularity_self': 0.15440899641780206,\n",
       "  'G_modularity_GeoPartition': 0.010148492253656575,\n",
       "  'G_modularity_GuniPartition': 0.16152813508292985},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(128.34546952001773),\n",
       "  'G_modularity_self': 0.28492854352345703,\n",
       "  'Geo_modularity_self': 0.5188148258029679,\n",
       "  'G_uni_modularity_self': 0.15801439545461565,\n",
       "  'G_modularity_GeoPartition': 0.010233132604825893,\n",
       "  'G_modularity_GuniPartition': 0.16306691412927782},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(150.21749915424036),\n",
       "  'G_modularity_self': 0.28477002519988864,\n",
       "  'Geo_modularity_self': 0.516531507010186,\n",
       "  'G_uni_modularity_self': 0.14095113003655135,\n",
       "  'G_modularity_GeoPartition': 0.010722396904104233,\n",
       "  'G_modularity_GuniPartition': 0.14625670327000231},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(96.30582528316278),\n",
       "  'G_modularity_self': 0.28536568279807034,\n",
       "  'Geo_modularity_self': 0.5182629714867364,\n",
       "  'G_uni_modularity_self': 0.14155864189294035,\n",
       "  'G_modularity_GeoPartition': 0.009473144217907873,\n",
       "  'G_modularity_GuniPartition': 0.15529251952565407},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(122.42378349993888),\n",
       "  'G_modularity_self': 0.2838541188794898,\n",
       "  'Geo_modularity_self': 0.5177762273908901,\n",
       "  'G_uni_modularity_self': 0.1500491160887455,\n",
       "  'G_modularity_GeoPartition': 0.008885988863222824,\n",
       "  'G_modularity_GuniPartition': 0.15339592097031168},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(104.15212398484994),\n",
       "  'G_modularity_self': 0.28614499645150154,\n",
       "  'Geo_modularity_self': 0.519032671579241,\n",
       "  'G_uni_modularity_self': 0.14114825575135678,\n",
       "  'G_modularity_GeoPartition': 0.008250305941431833,\n",
       "  'G_modularity_GuniPartition': 0.14666009978583658},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(95.29014492709538),\n",
       "  'G_modularity_self': 0.28629576006918805,\n",
       "  'Geo_modularity_self': 0.5192415922486384,\n",
       "  'G_uni_modularity_self': 0.15017063774843645,\n",
       "  'G_modularity_GeoPartition': 0.011441022560669504,\n",
       "  'G_modularity_GuniPartition': 0.15191102524073144},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(110.86240386078619),\n",
       "  'G_modularity_self': 0.284551581502173,\n",
       "  'Geo_modularity_self': 0.519113674861285,\n",
       "  'G_uni_modularity_self': 0.14210839708874015,\n",
       "  'G_modularity_GeoPartition': 0.009252165395529015,\n",
       "  'G_modularity_GuniPartition': 0.15062944518872076},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(127.2641961426493),\n",
       "  'G_modularity_self': 0.2861238550492897,\n",
       "  'Geo_modularity_self': 0.5173226076591281,\n",
       "  'G_uni_modularity_self': 0.14249378052712827,\n",
       "  'G_modularity_GeoPartition': 0.010507268763343028,\n",
       "  'G_modularity_GuniPartition': 0.1529383318632025},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(119.38517670079071),\n",
       "  'G_modularity_self': 0.2854904641563578,\n",
       "  'Geo_modularity_self': 0.5193201761388873,\n",
       "  'G_uni_modularity_self': 0.15460508979867393,\n",
       "  'G_modularity_GeoPartition': 0.009435785891393985,\n",
       "  'G_modularity_GuniPartition': 0.16124489181173207},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(141.61504304232307),\n",
       "  'G_modularity_self': 0.285330813476621,\n",
       "  'Geo_modularity_self': 0.5172222269632369,\n",
       "  'G_uni_modularity_self': 0.1579363023822034,\n",
       "  'G_modularity_GeoPartition': 0.010946024094362933,\n",
       "  'G_modularity_GuniPartition': 0.16582415911476311},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 20,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(120.2513513437583),\n",
       "  'G_modularity_self': 0.2842843914516499,\n",
       "  'Geo_modularity_self': 0.5184878484993546,\n",
       "  'G_uni_modularity_self': 0.14311023600642275,\n",
       "  'G_modularity_GeoPartition': 0.01018404970501468,\n",
       "  'G_modularity_GuniPartition': 0.15102421983980718},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 25,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(99.0858213873206),\n",
       "  'G_modularity_self': 0.28667392150547044,\n",
       "  'Geo_modularity_self': 0.5200571091866001,\n",
       "  'G_uni_modularity_self': 0.14795798857455272,\n",
       "  'G_modularity_GeoPartition': 0.008889175899397889,\n",
       "  'G_modularity_GuniPartition': 0.15675028356742907},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(106.44364439977888),\n",
       "  'G_modularity_self': 0.28769434698074553,\n",
       "  'Geo_modularity_self': 0.5190950387269752,\n",
       "  'G_uni_modularity_self': 0.14311845611843407,\n",
       "  'G_modularity_GeoPartition': 0.00986445349673298,\n",
       "  'G_modularity_GuniPartition': 0.15164248493135365},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(108.26240466518786),\n",
       "  'G_modularity_self': 0.2860048706289057,\n",
       "  'Geo_modularity_self': 0.5180202538612035,\n",
       "  'G_uni_modularity_self': 0.14190016272218772,\n",
       "  'G_modularity_GeoPartition': 0.009796366044380417,\n",
       "  'G_modularity_GuniPartition': 0.14771013022772886},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(125.39275160474568),\n",
       "  'G_modularity_self': 0.2856288336994525,\n",
       "  'Geo_modularity_self': 0.5182456016865594,\n",
       "  'G_uni_modularity_self': 0.1498523372027956,\n",
       "  'G_modularity_GeoPartition': 0.01093035691533676,\n",
       "  'G_modularity_GuniPartition': 0.15821528556957576},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 20,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(116.26860066243165),\n",
       "  'G_modularity_self': 0.28561954091870556,\n",
       "  'Geo_modularity_self': 0.517440093268971,\n",
       "  'G_uni_modularity_self': 0.14187453595719332,\n",
       "  'G_modularity_GeoPartition': 0.009624017280789534,\n",
       "  'G_modularity_GuniPartition': 0.15245378845936147},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(113.16638266415188),\n",
       "  'G_modularity_self': 0.28494277213111585,\n",
       "  'Geo_modularity_self': 0.51875553101346,\n",
       "  'G_uni_modularity_self': 0.14147875944243357,\n",
       "  'G_modularity_GeoPartition': 0.009769624934084288,\n",
       "  'G_modularity_GuniPartition': 0.15081935392414697},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 21,\n",
       "  'cluster_size_std_Geo': np.float64(106.61354673355277),\n",
       "  'G_modularity_self': 0.2874209037952355,\n",
       "  'Geo_modularity_self': 0.5189662533754958,\n",
       "  'G_uni_modularity_self': 0.14104602956098305,\n",
       "  'G_modularity_GeoPartition': 0.009313641045268021,\n",
       "  'G_modularity_GuniPartition': 0.15049986117782851},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(117.2545528552698),\n",
       "  'G_modularity_self': 0.28608269068123215,\n",
       "  'Geo_modularity_self': 0.5185628253812632,\n",
       "  'G_uni_modularity_self': 0.14123719775282156,\n",
       "  'G_modularity_GeoPartition': 0.009954042332791312,\n",
       "  'G_modularity_GuniPartition': 0.1551251742428087},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 16,\n",
       "  'cluster_size_std_Geo': np.float64(144.03658999087122),\n",
       "  'G_modularity_self': 0.28557575102695526,\n",
       "  'Geo_modularity_self': 0.5168036509803526,\n",
       "  'G_uni_modularity_self': 0.1419633651679038,\n",
       "  'G_modularity_GeoPartition': 0.011185963076149219,\n",
       "  'G_modularity_GuniPartition': 0.15057054473987452},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(106.0387274547693),\n",
       "  'G_modularity_self': 0.28649558564520455,\n",
       "  'Geo_modularity_self': 0.5187069224291997,\n",
       "  'G_uni_modularity_self': 0.14206013789816857,\n",
       "  'G_modularity_GeoPartition': 0.010038771945412125,\n",
       "  'G_modularity_GuniPartition': 0.157145368681369},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 15,\n",
       "  'cluster_size_std_Geo': np.float64(121.10952096368365),\n",
       "  'G_modularity_self': 0.28488198488549665,\n",
       "  'Geo_modularity_self': 0.5187283677838076,\n",
       "  'G_uni_modularity_self': 0.14984912538022416,\n",
       "  'G_modularity_GeoPartition': 0.009952062854278089,\n",
       "  'G_modularity_GuniPartition': 0.16279369175785527},\n",
       " {'G_num_comms': 19,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(101.90807229306083),\n",
       "  'G_modularity_self': 0.2877219563958125,\n",
       "  'Geo_modularity_self': 0.518956358503204,\n",
       "  'G_uni_modularity_self': 0.14180923662388362,\n",
       "  'G_modularity_GeoPartition': 0.009873877602721202,\n",
       "  'G_modularity_GuniPartition': 0.15364530942462273},\n",
       " {'G_num_comms': 14,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(95.62855439605379),\n",
       "  'G_modularity_self': 0.2835042337063896,\n",
       "  'Geo_modularity_self': 0.5191986799478733,\n",
       "  'G_uni_modularity_self': 0.14107977893206433,\n",
       "  'G_modularity_GeoPartition': 0.008745076986795563,\n",
       "  'G_modularity_GuniPartition': 0.1470510986383905},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 16,\n",
       "  'cluster_size_std_Geo': np.float64(123.7004930607436),\n",
       "  'G_modularity_self': 0.28810338828634025,\n",
       "  'Geo_modularity_self': 0.5182372905762248,\n",
       "  'G_uni_modularity_self': 0.14741973380196588,\n",
       "  'G_modularity_GeoPartition': 0.009673170195774277,\n",
       "  'G_modularity_GuniPartition': 0.15644882830978696},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(121.6396798755523),\n",
       "  'G_modularity_self': 0.28553352159606105,\n",
       "  'Geo_modularity_self': 0.5185396357728685,\n",
       "  'G_uni_modularity_self': 0.14201141954392665,\n",
       "  'G_modularity_GeoPartition': 0.008975306669907038,\n",
       "  'G_modularity_GuniPartition': 0.14889691278869213},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(106.82523187566342),\n",
       "  'G_modularity_self': 0.2859006844130529,\n",
       "  'Geo_modularity_self': 0.51875304328098,\n",
       "  'G_uni_modularity_self': 0.14294985949510164,\n",
       "  'G_modularity_GeoPartition': 0.009297670643165877,\n",
       "  'G_modularity_GuniPartition': 0.15253585890641597},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(95.63516461398392),\n",
       "  'G_modularity_self': 0.2861986112917161,\n",
       "  'Geo_modularity_self': 0.5186216656106349,\n",
       "  'G_uni_modularity_self': 0.1420823363670178,\n",
       "  'G_modularity_GeoPartition': 0.010246419704638505,\n",
       "  'G_modularity_GuniPartition': 0.15009541939486165},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(122.88268468344651),\n",
       "  'G_modularity_self': 0.28534640086893803,\n",
       "  'Geo_modularity_self': 0.5185051265022849,\n",
       "  'G_uni_modularity_self': 0.15391518841059065,\n",
       "  'G_modularity_GeoPartition': 0.010506673352652452,\n",
       "  'G_modularity_GuniPartition': 0.1601452336643607},\n",
       " {'G_num_comms': 14,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 16,\n",
       "  'cluster_size_std_Geo': np.float64(118.71200131494014),\n",
       "  'G_modularity_self': 0.2829929008809041,\n",
       "  'Geo_modularity_self': 0.5175889870356517,\n",
       "  'G_uni_modularity_self': 0.14950349115141462,\n",
       "  'G_modularity_GeoPartition': 0.01137362907197095,\n",
       "  'G_modularity_GuniPartition': 0.14909137374247836},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 20,\n",
       "  'G_uni_num_comms': 15,\n",
       "  'cluster_size_std_Geo': np.float64(114.3957494839734),\n",
       "  'G_modularity_self': 0.2857079143125333,\n",
       "  'Geo_modularity_self': 0.5180339368772002,\n",
       "  'G_uni_modularity_self': 0.15110617654554873,\n",
       "  'G_modularity_GeoPartition': 0.009970556138424982,\n",
       "  'G_modularity_GuniPartition': 0.15879652890500265},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(129.55866758772814),\n",
       "  'G_modularity_self': 0.2869531943743988,\n",
       "  'Geo_modularity_self': 0.5166419937655244,\n",
       "  'G_uni_modularity_self': 0.14209579404091663,\n",
       "  'G_modularity_GeoPartition': 0.010480165788084717,\n",
       "  'G_modularity_GuniPartition': 0.14752937666016655},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(97.19965659728634),\n",
       "  'G_modularity_self': 0.2856200230528171,\n",
       "  'Geo_modularity_self': 0.5181891474936863,\n",
       "  'G_uni_modularity_self': 0.1425244520892918,\n",
       "  'G_modularity_GeoPartition': 0.011245272865691665,\n",
       "  'G_modularity_GuniPartition': 0.1538390311387748},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(116.68664551965826),\n",
       "  'G_modularity_self': 0.28398531838749347,\n",
       "  'Geo_modularity_self': 0.5175836776672785,\n",
       "  'G_uni_modularity_self': 0.15024548422746054,\n",
       "  'G_modularity_GeoPartition': 0.010477750132443793,\n",
       "  'G_modularity_GuniPartition': 0.15668157719137504},\n",
       " {'G_num_comms': 14,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(131.99300812926168),\n",
       "  'G_modularity_self': 0.2829312596584844,\n",
       "  'Geo_modularity_self': 0.5177403312908373,\n",
       "  'G_uni_modularity_self': 0.14206091259370254,\n",
       "  'G_modularity_GeoPartition': 0.010682142817755244,\n",
       "  'G_modularity_GuniPartition': 0.15520537727714204},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 15,\n",
       "  'cluster_size_std_Geo': np.float64(118.45249819620732),\n",
       "  'G_modularity_self': 0.28746782748990674,\n",
       "  'Geo_modularity_self': 0.5189267454915153,\n",
       "  'G_uni_modularity_self': 0.1544478688773826,\n",
       "  'G_modularity_GeoPartition': 0.00921195598046476,\n",
       "  'G_modularity_GuniPartition': 0.1579903143727226},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 25,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(107.68323917862054),\n",
       "  'G_modularity_self': 0.2858771482132507,\n",
       "  'Geo_modularity_self': 0.5199683859268674,\n",
       "  'G_uni_modularity_self': 0.14269038533102466,\n",
       "  'G_modularity_GeoPartition': 0.010062242595088432,\n",
       "  'G_modularity_GuniPartition': 0.1491016902800758},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 12,\n",
       "  'cluster_size_std_Geo': np.float64(100.17118612118766),\n",
       "  'G_modularity_self': 0.28509420990670253,\n",
       "  'Geo_modularity_self': 0.5191761301262764,\n",
       "  'G_uni_modularity_self': 0.1566381929072185,\n",
       "  'G_modularity_GeoPartition': 0.00926509867726414,\n",
       "  'G_modularity_GuniPartition': 0.16417666868750438},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(111.64596014132808),\n",
       "  'G_modularity_self': 0.2865713981497786,\n",
       "  'Geo_modularity_self': 0.519390909404704,\n",
       "  'G_uni_modularity_self': 0.14182674630834402,\n",
       "  'G_modularity_GeoPartition': 0.009149009882131326,\n",
       "  'G_modularity_GuniPartition': 0.1549475326775656},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(115.01064449479203),\n",
       "  'G_modularity_self': 0.28587856779047766,\n",
       "  'Geo_modularity_self': 0.5181702103326108,\n",
       "  'G_uni_modularity_self': 0.14205001456430535,\n",
       "  'G_modularity_GeoPartition': 0.010472130476496758,\n",
       "  'G_modularity_GuniPartition': 0.154140618029318},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 15,\n",
       "  'cluster_size_std_Geo': np.float64(112.25761997579669),\n",
       "  'G_modularity_self': 0.28794714291437534,\n",
       "  'Geo_modularity_self': 0.5180293077734229,\n",
       "  'G_uni_modularity_self': 0.1541460588936593,\n",
       "  'G_modularity_GeoPartition': 0.00946613160662457,\n",
       "  'G_modularity_GuniPartition': 0.1574992062940822},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 20,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(118.28604101921748),\n",
       "  'G_modularity_self': 0.2864108317235077,\n",
       "  'Geo_modularity_self': 0.5180345127350817,\n",
       "  'G_uni_modularity_self': 0.1421082757436919,\n",
       "  'G_modularity_GeoPartition': 0.010464611870367735,\n",
       "  'G_modularity_GuniPartition': 0.15567398597259563},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(101.8825743535964),\n",
       "  'G_modularity_self': 0.2861276520598569,\n",
       "  'Geo_modularity_self': 0.5175580801631039,\n",
       "  'G_uni_modularity_self': 0.15263584284456935,\n",
       "  'G_modularity_GeoPartition': 0.012193444868292146,\n",
       "  'G_modularity_GuniPartition': 0.1572939561114698},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(118.72856686489591),\n",
       "  'G_modularity_self': 0.2863840641579232,\n",
       "  'Geo_modularity_self': 0.5183805921410953,\n",
       "  'G_uni_modularity_self': 0.14342779444535003,\n",
       "  'G_modularity_GeoPartition': 0.009996587323256596,\n",
       "  'G_modularity_GuniPartition': 0.1566596399127143},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 23,\n",
       "  'cluster_size_std_Geo': np.float64(127.33333003427717),\n",
       "  'G_modularity_self': 0.28670946758831733,\n",
       "  'Geo_modularity_self': 0.51854932007466,\n",
       "  'G_uni_modularity_self': 0.1408294887687247,\n",
       "  'G_modularity_GeoPartition': 0.009207363160702323,\n",
       "  'G_modularity_GuniPartition': 0.148912759486371},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(131.08524766353173),\n",
       "  'G_modularity_self': 0.28588925462625747,\n",
       "  'Geo_modularity_self': 0.5183248305234351,\n",
       "  'G_uni_modularity_self': 0.15078554358698176,\n",
       "  'G_modularity_GeoPartition': 0.010482336287560592,\n",
       "  'G_modularity_GuniPartition': 0.16063040082300378},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(126.24036749585105),\n",
       "  'G_modularity_self': 0.2855770109533238,\n",
       "  'Geo_modularity_self': 0.5183979501576437,\n",
       "  'G_uni_modularity_self': 0.1462777611217798,\n",
       "  'G_modularity_GeoPartition': 0.010860496491135553,\n",
       "  'G_modularity_GuniPartition': 0.15832712756644302},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 20,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(121.54212232802256),\n",
       "  'G_modularity_self': 0.2860731010025064,\n",
       "  'Geo_modularity_self': 0.5175471829050163,\n",
       "  'G_uni_modularity_self': 0.1460466901447323,\n",
       "  'G_modularity_GeoPartition': 0.011200397471178847,\n",
       "  'G_modularity_GuniPartition': 0.1575732957298991},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(133.25912277083657),\n",
       "  'G_modularity_self': 0.28796759551518025,\n",
       "  'Geo_modularity_self': 0.5184172492368676,\n",
       "  'G_uni_modularity_self': 0.14232345626208442,\n",
       "  'G_modularity_GeoPartition': 0.011073434748531008,\n",
       "  'G_modularity_GuniPartition': 0.14794865503692597},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(133.8469063106148),\n",
       "  'G_modularity_self': 0.2870909097401172,\n",
       "  'Geo_modularity_self': 0.5181422190479379,\n",
       "  'G_uni_modularity_self': 0.14301977680104944,\n",
       "  'G_modularity_GeoPartition': 0.011028301062803534,\n",
       "  'G_modularity_GuniPartition': 0.15351659317952854},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(121.91835264119919),\n",
       "  'G_modularity_self': 0.28580354970187777,\n",
       "  'Geo_modularity_self': 0.5179893903203906,\n",
       "  'G_uni_modularity_self': 0.14112194180950605,\n",
       "  'G_modularity_GeoPartition': 0.009063048197212806,\n",
       "  'G_modularity_GuniPartition': 0.1491010444238635},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(95.1411141264502),\n",
       "  'G_modularity_self': 0.28495165965644853,\n",
       "  'Geo_modularity_self': 0.519707329816278,\n",
       "  'G_uni_modularity_self': 0.1438417369260957,\n",
       "  'G_modularity_GeoPartition': 0.009806709100448601,\n",
       "  'G_modularity_GuniPartition': 0.15984903929030425},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(114.38557145425335),\n",
       "  'G_modularity_self': 0.2850270352851762,\n",
       "  'Geo_modularity_self': 0.517762107150457,\n",
       "  'G_uni_modularity_self': 0.14302023708285716,\n",
       "  'G_modularity_GeoPartition': 0.009825487807311977,\n",
       "  'G_modularity_GuniPartition': 0.14729754948589074},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(116.52347864005847),\n",
       "  'G_modularity_self': 0.28426761051138283,\n",
       "  'Geo_modularity_self': 0.5186833815944846,\n",
       "  'G_uni_modularity_self': 0.14935028944560613,\n",
       "  'G_modularity_GeoPartition': 0.00964501790056995,\n",
       "  'G_modularity_GuniPartition': 0.15688088828494556},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(129.36731771418152),\n",
       "  'G_modularity_self': 0.2858959635796338,\n",
       "  'Geo_modularity_self': 0.5177987889453891,\n",
       "  'G_uni_modularity_self': 0.14229696186588253,\n",
       "  'G_modularity_GeoPartition': 0.01077546058750102,\n",
       "  'G_modularity_GuniPartition': 0.1519638996298268},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(109.98509478279394),\n",
       "  'G_modularity_self': 0.2870544452178672,\n",
       "  'Geo_modularity_self': 0.5178711920750032,\n",
       "  'G_uni_modularity_self': 0.14192651980460225,\n",
       "  'G_modularity_GeoPartition': 0.009454583169710212,\n",
       "  'G_modularity_GuniPartition': 0.14671102031814795},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(127.27945221800768),\n",
       "  'G_modularity_self': 0.28624727162066754,\n",
       "  'Geo_modularity_self': 0.5178709247518545,\n",
       "  'G_uni_modularity_self': 0.14252023888239615,\n",
       "  'G_modularity_GeoPartition': 0.009979762190261325,\n",
       "  'G_modularity_GuniPartition': 0.1534855981110963},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 12,\n",
       "  'cluster_size_std_Geo': np.float64(91.0389015598399),\n",
       "  'G_modularity_self': 0.2839231324836968,\n",
       "  'Geo_modularity_self': 0.5187967198981464,\n",
       "  'G_uni_modularity_self': 0.15854760650474797,\n",
       "  'G_modularity_GeoPartition': 0.00849913305950943,\n",
       "  'G_modularity_GuniPartition': 0.16515536064253136},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(135.05245251588568),\n",
       "  'G_modularity_self': 0.2835310440203083,\n",
       "  'Geo_modularity_self': 0.5193115991259044,\n",
       "  'G_uni_modularity_self': 0.14157659516313717,\n",
       "  'G_modularity_GeoPartition': 0.011361413565983507,\n",
       "  'G_modularity_GuniPartition': 0.1495421902543086},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(90.54829540997937),\n",
       "  'G_modularity_self': 0.28491017598799667,\n",
       "  'Geo_modularity_self': 0.5173669043852975,\n",
       "  'G_uni_modularity_self': 0.14203638323172552,\n",
       "  'G_modularity_GeoPartition': 0.010257864453420949,\n",
       "  'G_modularity_GuniPartition': 0.15212229153941545},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(108.26647756941784),\n",
       "  'G_modularity_self': 0.2852398367770236,\n",
       "  'Geo_modularity_self': 0.5189147492021045,\n",
       "  'G_uni_modularity_self': 0.1465110786974211,\n",
       "  'G_modularity_GeoPartition': 0.01040300525648304,\n",
       "  'G_modularity_GuniPartition': 0.15572616246609877},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(125.95260599493803),\n",
       "  'G_modularity_self': 0.2860831724828655,\n",
       "  'Geo_modularity_self': 0.5178247138625788,\n",
       "  'G_uni_modularity_self': 0.151393379909478,\n",
       "  'G_modularity_GeoPartition': 0.0100253358540773,\n",
       "  'G_modularity_GuniPartition': 0.15392752342111374},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 21,\n",
       "  'cluster_size_std_Geo': np.float64(117.59519618287668),\n",
       "  'G_modularity_self': 0.28449824058481865,\n",
       "  'Geo_modularity_self': 0.5188283299174806,\n",
       "  'G_uni_modularity_self': 0.14110634557296978,\n",
       "  'G_modularity_GeoPartition': 0.010279686041275727,\n",
       "  'G_modularity_GuniPartition': 0.1484083247789871},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(107.61289489365245),\n",
       "  'G_modularity_self': 0.28499269706867264,\n",
       "  'Geo_modularity_self': 0.5174338278802627,\n",
       "  'G_uni_modularity_self': 0.15376813034877723,\n",
       "  'G_modularity_GeoPartition': 0.010302589851552801,\n",
       "  'G_modularity_GuniPartition': 0.16692797484046223},\n",
       " {'G_num_comms': 14,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(121.52821308635998),\n",
       "  'G_modularity_self': 0.2838134678766587,\n",
       "  'Geo_modularity_self': 0.5176003632995801,\n",
       "  'G_uni_modularity_self': 0.14217815912556778,\n",
       "  'G_modularity_GeoPartition': 0.010150616685935922,\n",
       "  'G_modularity_GuniPartition': 0.15003984746397142},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 12,\n",
       "  'cluster_size_std_Geo': np.float64(98.63081570778662),\n",
       "  'G_modularity_self': 0.2877013378273664,\n",
       "  'Geo_modularity_self': 0.5195889255437651,\n",
       "  'G_uni_modularity_self': 0.15468211757923836,\n",
       "  'G_modularity_GeoPartition': 0.00896250483117513,\n",
       "  'G_modularity_GuniPartition': 0.15391650716789837},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(107.10591955879539),\n",
       "  'G_modularity_self': 0.2867604635154163,\n",
       "  'Geo_modularity_self': 0.5180023131656631,\n",
       "  'G_uni_modularity_self': 0.14226990401527156,\n",
       "  'G_modularity_GeoPartition': 0.009479927424468487,\n",
       "  'G_modularity_GuniPartition': 0.1511344452435664},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 15,\n",
       "  'cluster_size_std_Geo': np.float64(141.82285103036168),\n",
       "  'G_modularity_self': 0.28533468246551635,\n",
       "  'Geo_modularity_self': 0.5171965485358772,\n",
       "  'G_uni_modularity_self': 0.15002105868842402,\n",
       "  'G_modularity_GeoPartition': 0.011099145510503696,\n",
       "  'G_modularity_GuniPartition': 0.16171119941868262},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(117.12848195654306),\n",
       "  'G_modularity_self': 0.2868546920185682,\n",
       "  'Geo_modularity_self': 0.5187852641248911,\n",
       "  'G_uni_modularity_self': 0.14089809426066494,\n",
       "  'G_modularity_GeoPartition': 0.009555090726601666,\n",
       "  'G_modularity_GuniPartition': 0.14810525643286246},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(111.57342947713516),\n",
       "  'G_modularity_self': 0.2873760583578108,\n",
       "  'Geo_modularity_self': 0.5182448322875728,\n",
       "  'G_uni_modularity_self': 0.14229073302633027,\n",
       "  'G_modularity_GeoPartition': 0.011520515952681864,\n",
       "  'G_modularity_GuniPartition': 0.1480777871972761},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 21,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(113.54110606489576),\n",
       "  'G_modularity_self': 0.28602028116074496,\n",
       "  'Geo_modularity_self': 0.518026658552275,\n",
       "  'G_uni_modularity_self': 0.1453199579074224,\n",
       "  'G_modularity_GeoPartition': 0.010433788439386407,\n",
       "  'G_modularity_GuniPartition': 0.14998459078578177},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 15,\n",
       "  'cluster_size_std_Geo': np.float64(105.2774030702801),\n",
       "  'G_modularity_self': 0.28594053434763333,\n",
       "  'Geo_modularity_self': 0.5192012702235735,\n",
       "  'G_uni_modularity_self': 0.15473602113831209,\n",
       "  'G_modularity_GeoPartition': 0.009048087063225154,\n",
       "  'G_modularity_GuniPartition': 0.16225545288667914},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(98.12882618744413),\n",
       "  'G_modularity_self': 0.28512409869434224,\n",
       "  'Geo_modularity_self': 0.5185429343384895,\n",
       "  'G_uni_modularity_self': 0.1413121635468775,\n",
       "  'G_modularity_GeoPartition': 0.00880413590091674,\n",
       "  'G_modularity_GuniPartition': 0.1461788951328928},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(132.77863130246354),\n",
       "  'G_modularity_self': 0.2869664098653399,\n",
       "  'Geo_modularity_self': 0.5181463307670202,\n",
       "  'G_uni_modularity_self': 0.14199595401005466,\n",
       "  'G_modularity_GeoPartition': 0.011445374365246994,\n",
       "  'G_modularity_GuniPartition': 0.1536121313919498},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 24,\n",
       "  'G_uni_num_comms': 12,\n",
       "  'cluster_size_std_Geo': np.float64(85.64411789816948),\n",
       "  'G_modularity_self': 0.2845279184717155,\n",
       "  'Geo_modularity_self': 0.5195615747783844,\n",
       "  'G_uni_modularity_self': 0.15801198443554398,\n",
       "  'G_modularity_GeoPartition': 0.009652627035645428,\n",
       "  'G_modularity_GuniPartition': 0.1634315091862038},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 15,\n",
       "  'cluster_size_std_Geo': np.float64(90.57590077748547),\n",
       "  'G_modularity_self': 0.2864026113775645,\n",
       "  'Geo_modularity_self': 0.5188130619151509,\n",
       "  'G_uni_modularity_self': 0.15002000707476196,\n",
       "  'G_modularity_GeoPartition': 0.009127777990579043,\n",
       "  'G_modularity_GuniPartition': 0.15294420164771588},\n",
       " {'G_num_comms': 20,\n",
       "  'Geo_num_comms': 20,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(120.52463441139327),\n",
       "  'G_modularity_self': 0.2884450662906279,\n",
       "  'Geo_modularity_self': 0.5171722064113631,\n",
       "  'G_uni_modularity_self': 0.1468145481598967,\n",
       "  'G_modularity_GeoPartition': 0.011561701793093923,\n",
       "  'G_modularity_GuniPartition': 0.1547239949547387},\n",
       " {'G_num_comms': 15,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 16,\n",
       "  'cluster_size_std_Geo': np.float64(111.59649160084804),\n",
       "  'G_modularity_self': 0.28537161155196683,\n",
       "  'Geo_modularity_self': 0.5189352246557601,\n",
       "  'G_uni_modularity_self': 0.15031469572816572,\n",
       "  'G_modularity_GeoPartition': 0.010560726559372718,\n",
       "  'G_modularity_GuniPartition': 0.15643957160469837},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(119.28648929751273),\n",
       "  'G_modularity_self': 0.2856552086647521,\n",
       "  'Geo_modularity_self': 0.5183995744682013,\n",
       "  'G_uni_modularity_self': 0.14332747713264946,\n",
       "  'G_modularity_GeoPartition': 0.01048950441285118,\n",
       "  'G_modularity_GuniPartition': 0.14917880787057114},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 19,\n",
       "  'cluster_size_std_Geo': np.float64(87.9265870527442),\n",
       "  'G_modularity_self': 0.287400953482367,\n",
       "  'Geo_modularity_self': 0.5191494442138743,\n",
       "  'G_uni_modularity_self': 0.14247958957220247,\n",
       "  'G_modularity_GeoPartition': 0.009406545412970674,\n",
       "  'G_modularity_GuniPartition': 0.1527894683983893},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 14,\n",
       "  'cluster_size_std_Geo': np.float64(111.73666043624283),\n",
       "  'G_modularity_self': 0.28562341603430275,\n",
       "  'Geo_modularity_self': 0.5183865412431374,\n",
       "  'G_uni_modularity_self': 0.15354510103769486,\n",
       "  'G_modularity_GeoPartition': 0.009343554161961445,\n",
       "  'G_modularity_GuniPartition': 0.15850483484230415},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 13,\n",
       "  'cluster_size_std_Geo': np.float64(101.68341097766601),\n",
       "  'G_modularity_self': 0.2876231861174161,\n",
       "  'Geo_modularity_self': 0.5189354450891929,\n",
       "  'G_uni_modularity_self': 0.15365418250681878,\n",
       "  'G_modularity_GeoPartition': 0.00977947466671841,\n",
       "  'G_modularity_GuniPartition': 0.16264168421849456},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 16,\n",
       "  'cluster_size_std_Geo': np.float64(99.80086031806961),\n",
       "  'G_modularity_self': 0.28551925417064994,\n",
       "  'Geo_modularity_self': 0.5188728604471827,\n",
       "  'G_uni_modularity_self': 0.151948671644082,\n",
       "  'G_modularity_GeoPartition': 0.009687136800281663,\n",
       "  'G_modularity_GuniPartition': 0.15311515906347165},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 12,\n",
       "  'cluster_size_std_Geo': np.float64(134.86287035968382),\n",
       "  'G_modularity_self': 0.2848974851252077,\n",
       "  'Geo_modularity_self': 0.5170234594843621,\n",
       "  'G_uni_modularity_self': 0.1577724446423292,\n",
       "  'G_modularity_GeoPartition': 0.010567785928962752,\n",
       "  'G_modularity_GuniPartition': 0.15937079363143758},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 21,\n",
       "  'cluster_size_std_Geo': np.float64(128.14584440400915),\n",
       "  'G_modularity_self': 0.2866308284324784,\n",
       "  'Geo_modularity_self': 0.5177679064448918,\n",
       "  'G_uni_modularity_self': 0.14141962787449097,\n",
       "  'G_modularity_GeoPartition': 0.009993877838399542,\n",
       "  'G_modularity_GuniPartition': 0.1555310011559947},\n",
       " {'G_num_comms': 18,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 17,\n",
       "  'cluster_size_std_Geo': np.float64(107.25963903206674),\n",
       "  'G_modularity_self': 0.2878011333419169,\n",
       "  'Geo_modularity_self': 0.5180750867873005,\n",
       "  'G_uni_modularity_self': 0.14687143391085608,\n",
       "  'G_modularity_GeoPartition': 0.010045543902307707,\n",
       "  'G_modularity_GuniPartition': 0.1552928308121733},\n",
       " {'G_num_comms': 16,\n",
       "  'Geo_num_comms': 22,\n",
       "  'G_uni_num_comms': 18,\n",
       "  'cluster_size_std_Geo': np.float64(94.9229026000392),\n",
       "  'G_modularity_self': 0.2861662784354344,\n",
       "  'Geo_modularity_self': 0.5187985736845026,\n",
       "  'G_uni_modularity_self': 0.14156576493846101,\n",
       "  'G_modularity_GeoPartition': 0.009157336664077326,\n",
       "  'G_modularity_GuniPartition': 0.1524830580612338},\n",
       " {'G_num_comms': 17,\n",
       "  'Geo_num_comms': 23,\n",
       "  'G_uni_num_comms': 20,\n",
       "  'cluster_size_std_Geo': np.float64(114.86492437059115),\n",
       "  'G_modularity_self': 0.2872391533669921,\n",
       "  'Geo_modularity_self': 0.5185153439141506,\n",
       "  'G_uni_modularity_self': 0.14288842163305432,\n",
       "  'G_modularity_GeoPartition': 0.009256725343396768,\n",
       "  'G_modularity_GuniPartition': 0.1614882728374725}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5225316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   G_num_comms  Geo_num_comms  G_uni_num_comms  cluster_size_std_Geo  \\\n",
      "0           17             23               16             88.853291   \n",
      "1           17             22               14            113.774870   \n",
      "2           15             24               21            102.075944   \n",
      "3           18             19               12            107.310459   \n",
      "4           15             25               16            100.535765   \n",
      "\n",
      "   G_modularity_self  Geo_modularity_self  G_uni_modularity_self  \\\n",
      "0           0.286556             0.518317               0.146155   \n",
      "1           0.286854             0.518279               0.156069   \n",
      "2           0.284645             0.518875               0.142195   \n",
      "3           0.287641             0.516415               0.156112   \n",
      "4           0.284027             0.519459               0.147119   \n",
      "\n",
      "   G_modularity_GeoPartition  G_modularity_GuniPartition  \n",
      "0                   0.010055                    0.154570  \n",
      "1                   0.011380                    0.164181  \n",
      "2                   0.009073                    0.152311  \n",
      "3                   0.010956                    0.162541  \n",
      "4                   0.009055                    0.160829  \n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results_list)\n",
    "df_results.to_csv(\"louvain_results.csv\", index=False)\n",
    "print(df_results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "255c8078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All best runs (closest to 14 communities): [3 7]\n",
      "Number of communities for these runs: [19 19]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "geo_num_comms = np.array(results['Geo_num_comms'])\n",
    "target = 14\n",
    "\n",
    "diffs = np.abs(geo_num_comms - target)\n",
    "\n",
    "min_diff = np.min(diffs)\n",
    "best_indices = np.where(diffs == min_diff)[0]\n",
    "\n",
    "print(\"All best runs (closest to 14 communities):\", best_indices)\n",
    "print(\"Number of communities for these runs:\", geo_num_comms[best_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ae8b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run index (closest to 14 AND highest modularity): 7\n",
      "Number of communities: 19\n",
      "Modularity: 0.5171688730189038\n"
     ]
    }
   ],
   "source": [
    "geo_num_comms = np.array(results['Geo_num_comms'])\n",
    "target = 14\n",
    "\n",
    "diffs = np.abs(geo_num_comms - target)\n",
    "min_diff = np.min(diffs)\n",
    "best_runs = np.where(diffs == min_diff)[0]\n",
    "\n",
    "geo_modularity_self = np.array(results['Geo_modularity_self'])\n",
    "best_mod_index = best_runs[np.argmax(geo_modularity_self[best_runs])]\n",
    "\n",
    "print(\"Best run index (closest to 14 AND highest modularity):\", best_mod_index)\n",
    "print(\"Number of communities:\", geo_num_comms[best_mod_index])\n",
    "print(\"Modularity:\", geo_modularity_self[best_mod_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All best runs (closest to 14 communities): [35 41 46 76]\n",
      "Number of communities for these runs: [14 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "G_num_comms = np.array(results['G_num_comms'])\n",
    "target = 14\n",
    "\n",
    "diffs = np.abs(G_num_comms - target)\n",
    "\n",
    "min_diff = np.min(diffs)\n",
    "best_indices = np.where(diffs == min_diff)[0]\n",
    "\n",
    "print(\"All best runs (closest to 14 communities):\", best_indices)\n",
    "print(\"Number of communities for these runs:\", G_num_comms[best_indices])\n",
    "\n",
    "geo_modularity_self = np.array(results['Geo_modularity_self'])\n",
    "best_mod_index = best_runs[np.argmax(geo_modularity_self[best_runs])]\n",
    "\n",
    "print(\"Best run index (closest to 14 AND highest modularity):\", best_mod_index)\n",
    "print(\"Number of communities:\", geo_num_comms[best_mod_index])\n",
    "print(\"Modularity:\", geo_modularity_self[best_mod_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b123199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run index (closest to 14 AND highest modularity): 76\n",
      "Number of communities: 14\n",
      "Modularity: 0.2838134678766587\n"
     ]
    }
   ],
   "source": [
    "G_num_comms = np.array(results['G_num_comms'])\n",
    "target = 14\n",
    "\n",
    "diffs = np.abs(G_num_comms - target)\n",
    "min_diff = np.min(diffs)\n",
    "best_runs = np.where(diffs == min_diff)[0]\n",
    "\n",
    "G_modularity_self = np.array(results['G_modularity_self'])\n",
    "best_mod_index = best_runs[np.argmax(G_modularity_self[best_runs])]\n",
    "\n",
    "print(\"Best run index (closest to 14 AND highest modularity):\", best_mod_index)\n",
    "print(\"Number of communities:\", G_num_comms[best_mod_index])\n",
    "print(\"Modularity:\", G_modularity_self[best_mod_index])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
